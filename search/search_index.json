{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Introduction","text":"<p>The <code>aiida-defects-neb</code> package is currently mainly a testing ground for developing workflows to run NEB calculations for calculating the migration barrier of defects.</p>"},{"location":"#installation","title":"Installation","text":"<p>First, clone the repository:</p> <pre><code>git clone https://github.com/verdi-group/aiida-defects-neb.git\n</code></pre> <p>Create a Python environment with the tool of your choice and install the package from the source code in editable mode (<code>-e</code>):</p> <pre><code>pip install -e aiida-defects-neb\n</code></pre> <p>This will also install AiiDA (via the <code>aiida-core</code> package). All you need now is to set up a profile, let's call it <code>neb</code>:</p> <pre><code>verdi presto -p neb\n</code></pre>"},{"location":"#first-steps","title":"First steps","text":"<ul> <li> <p>\u2699\ufe0f Set up</p> <p>First steps: start by setting up AiiDA and the necessary computer and VASP code.</p> <p>\u2192 Go to the setup page</p> </li> <li> <p>\ud83d\ude80 Quickstart</p> <p>After performing the required setup, try running your first NEB workflow with the quick start tutorial!</p> <p>\u2192 Go to the tutorial</p> </li> </ul> <p>Warning</p> <p>If you found your way to this repository and are interested in running the workflows, feel free! However, be aware that the API of the workflows can still change drastically until we get to a first stable release (v1.0.0), which may still take quite some time. Here be dragons! \ud83d\udc09</p>"},{"location":"developer/","title":"Developer Guide","text":""},{"location":"developer/#quick-start","title":"Quick start","text":"<p>Thanks for contributing! \ud83d\ude4f Below you can find an overview of the commands to get you up and running quickly.</p> <p>First clone the repository from GitHub</p> <pre><code>git clone &lt;GITHUB-REPO&gt;\n</code></pre> <p>and install the package locally in editable mode (<code>-e</code>):</p> <pre><code>cd aiida-defects-neb\npip install -e .\n</code></pre> <p>Note</p> <p>We support various tools for developers. Select your preferred one from the tabs below. If you don't know <code>uv</code> or Hatch, stick with the default for now.</p> DefaultuvHatch <p>The \"default\" approach to developing is to install the development extras in your current environment:</p> <pre><code>pip install -e .[pre-commit,tests,docs]\n</code></pre> <p>\ud83d\udd27 Pre-commit</p> <p>To make sure your changes adhere to our formatting/linting preferences, install the pre-commit hooks:</p> <pre><code>pre-commit install\n</code></pre> <p>They will then run on every <code>git commit</code>. You can also run them on e.g. all files using:</p> <pre><code>pre-commit run -a\n</code></pre> <p>Drop the <code>-a</code> option in case you only want to run on staged files.</p> <p>\ud83e\uddea Tests</p> <p>You can run all tests in the <code>tests</code> directory with <code>pytest</code>:</p> <pre><code>pytest\n</code></pre> <p>Or select the test module:</p> <pre><code>pytest tests/parsers/test_pw.py\n</code></pre> <p>See the <code>pytest</code> documentation for more information.</p> <p>\ud83d\udcda Documentation</p> <p>We use Material for MkDocs as our documentation framework. Start the documentation server with:</p> <pre><code>mkdocs serve\n</code></pre> <p>and open the documentation in your browser via the link shown. Every time you save a file, the corresponding documentation page is updated automatically!</p> <p>A GitHub action is set up to automatically deploy the documentation to GitHub Pages. See the corresponding GitHub Pages documentation for the steps required.</p> <p><code>uv</code> is a Python package and project manager. See the documentation on how to install <code>uv</code>.</p> <p>\ud83d\udd27 Pre-commit</p> <p>To make sure your changes adhere to our formatting/linting preferences, install the pre-commit hooks:</p> <pre><code>uvx pre-commit install\n</code></pre> <p>They will then run on every <code>git commit</code>. You can also run them on e.g. all files using:</p> <pre><code>uvx pre-commit run -a\n</code></pre> <p>Drop the <code>-a</code> option in case you only want to run on staged files.</p> <p>Note</p> <p>Here we use the <code>uvx</code> command to run the <code>pre-commit</code> tool without installing it. Alternatively you can also install <code>pre-commit</code> as a tool and omit <code>uvx</code>.</p> <p>\ud83e\uddea Tests</p> <p>You can run all tests in the <code>tests</code> directory with <code>pytest</code>:</p> <pre><code>uv run pytest\n</code></pre> <p>Or select the test module:</p> <pre><code>uv run pytest tests/parsers/test_pw.py\n</code></pre> <p>See the <code>pytest</code> documentation for more information.</p> <p>\ud83d\udcda Documentation</p> <p>We use Material for MkDocs as our documentation framework. Start the documentation server with:</p> <pre><code>mkdocs serve\n</code></pre> <p>and open the documentation in your browser via the link shown. Every time you save a file, the corresponding documentation page is updated automatically!</p> <p>A GitHub action is set up to automatically deploy the documentation to GitHub Pages. See the corresponding GitHub Pages documentation for the steps required.</p> <p>You can use Hatch to run development tools in isolated environments. To see a table of the available environments and their scripts, run:</p> <pre><code>hatch env show\n</code></pre> <p>\ud83d\udd27 Pre-commit</p> <p>To make sure your changes adhere to our formatting/linting preferences, install the pre-commit hooks:</p> <pre><code>hatch run pre-commit:install\n</code></pre> <p>They will then run on every <code>git commit</code>. You can also run them on e.g. all files using:</p> <pre><code>hatch run pre-commit:run -a\n</code></pre> <p>Drop the <code>-a</code> option in case you only want to run on staged files.</p> <p>\ud83e\uddea Tests</p> <p>You can run all tests in the <code>tests</code> directory using:</p> <pre><code>hatch test\n</code></pre> <p>Or select the test module:</p> <pre><code>hatch test tests/parsers/test_pw.py\n</code></pre> <p>You can also run the tests for a specific Python version with the <code>-py</code> option:</p> <pre><code>hatch test -py 3.11\n</code></pre> <p>Or all supported Python <code>versions</code> with <code>--all</code>:</p> <pre><code>hatch test --all\n</code></pre> <p>See the Hatch documentation for more information.</p> <p>\ud83d\udcda Documentation</p> <p>We use Material for MkDocs as our documentation framework. Start the documentation server with:</p> <pre><code>hatch run docs:serve\n</code></pre> <p>and open the documentation in your browser via the link shown. Every time you save a file, the corresponding documentation page is updated automatically!</p> <p>A GitHub action is set up to automatically deploy the documentation to GitHub Pages. See the corresponding GitHub Pages documentation for the steps required.</p>"},{"location":"developer/#pre-commit-rules","title":"Pre-commit rules","text":"<p>From the extensive Ruff ruleset, we ignore the following globally:</p> Code Rule Rationale / Note <code>TRY003</code> raise-vanilla-args Formatting warning/exception messages beforehand makes the code less readable, for a minor benefit in readability of the exception. <code>EM101</code> raw-string-in-exception Same as <code>TRY003</code> <code>EM102</code> f-string-in-exception Same as <code>TRY003</code> <code>PLR2004</code> magic-value-comparison We have a lot of \u201cmagic values\u201d to compare with in scientific code; naming them all would reduce readability for little benefit. <code>FBT002</code> boolean-default-value-positional-argument We understand the concept, but adhering to this rule is not a small change in syntax; disable for now. <code>TID252</code> relative-imports We don\u2019t mind relative imports; as long as you don\u2019t go up a level, they\u2019re more readable (less verbose). <p>And the following rules for the files in the <code>tests</code> directory:</p> Code Rule Rationale / Note <code>INP001</code> implicit-namespace-package When tests are not part of the package, there is no need for <code>__init__.py</code> files. <code>S101</code> assert Asserts should not be used in production environments, but are fine for tests."},{"location":"quickstart/","title":"Quickstart","text":""},{"location":"setup/","title":"Setup","text":"<p>Once you have installed the package and set up your profile, you still need to tell AiiDA:</p> <ol> <li>Which computer to run on.</li> <li>What VASP code you want to run.</li> <li>Where to find the VASP pseudopotentials.</li> </ol> <p>These instructions show you exactly how to do that. First we'll import some tools and load your AiiDA profile:</p> <pre><code>from aiida import orm, load_profile\nfrom aiida.common.exceptions import NotExistent\n\nload_profile()\n</code></pre> <p>Important</p> <p>You need to load your AiiDA profile to be able to interact with the database, where your computer/code/calculations are stored. Hence, you have to execute the code above before running any of the cells below.</p>"},{"location":"setup/#computers","title":"Computers","text":"<p>First we'll set up a computers for AiiDA to run on. The \"transport\" that we'll use (identified via <code>core.ssh_async</code>) will automatically use the configuration from your <code>~/.ssh/config</code>. Hence the instructions below assume that you've already set up you connection with the computer.</p> <p>Warning</p> <p>Most of the setup and configuration is specific and correct for the Pawsey supercomputer. But you need to update the <code>working_directory</code> in the cell below to the root directory on <code>/scratch</code> where you want to run your AiiDA calculations.</p> <pre><code>working_directory = '/scratch/pawsey1141/mbercx/aiida-defect-neb/aiida'\n</code></pre> <pre><code>try:\n    pawsey = orm.load_computer('pawsey')\nexcept NotExistent:\n    pawsey = orm.Computer(\n        label='pawsey',\n        hostname='setonix.pawsey.org.au',\n        transport_type='core.ssh_async',\n        scheduler_type='core.slurm',\n    )\n    pawsey.set_workdir(working_directory)\n    pawsey.set_mpirun_command('srun -N {num_machines} -n {tot_num_mpiprocs} -c 1 -m block:block:block'.split())\n    pawsey.set_default_mpiprocs_per_machine(64)\n    pawsey.set_use_double_quotes(True)\n    pawsey.configure()\n    pawsey.store()\n</code></pre> <p>Note</p> <p>The code snippets for setting up the computer is wrapped in <code>try-except</code> blocks to avoid trying to set up the same computer multiple times. This would fail, since two computers can't have the same label.</p> <p>We can see if the computers have been set up properly using the CLI command:</p> <pre><code>!verdi computer list\n</code></pre> <p>As well as test them:</p> <pre><code>!verdi computer test pawsey\n</code></pre>"},{"location":"setup/#codes","title":"Codes","text":"<p>Next, we'll set up the VASP code we need to run on <code>pawsey</code>:</p> <pre><code>code_label = 'vasp-6.4.3-vtst'\n\ntry:\n    orm.load_code(f'{code_label}@pawsey')\nexcept NotExistent:\n    code = orm.InstalledCode(\n        label=code_label,\n        computer=pawsey,\n        default_calc_job_plugin='vasp.vasp',\n        filepath_executable='/software/projects/pawsey1141/cverdi/vasp.6.4.3-vtst/bin/vasp_std'\n    )\n    code.description = 'VASP 6.4.3 std version with VTST'\n    code.use_double_quotes = True\n    code.prepend_text = \"\"\"\nmodule load hdf5/1.14.3-api-v112 netlib-scalapack/2.2.0 fftw/3.3.10\nexport OMP_NUM_THREADS=1\nexport MPICH_OFI_STARTUP_CONNECT=1\nexport MPICH_OFI_VERBOSE=1\nexport FI_CXI_DEFAULT_VNI=$(od -vAn -N4 -tu &lt; /dev/urandom)\nulimit -s unlimited\n\"\"\"\n    code.store()\n</code></pre> <pre><code>!verdi code list\n</code></pre>"},{"location":"setup/#pseudo-potentials","title":"Pseudo potentials","text":"<p>In order to set up the input <code>POTCAR</code> files, the <code>aiida-vasp</code> plugin needs access to the VASP pseudo potentials.</p> <p>Important</p> <p>Again, change the path below to the one where you have the VASP POTCAR files stored! If you run <code>ls</code> in this directory you should see all the element/POTCAR directories.</p> <pre><code>path_to_potcar_files = '/Users/mbercx/tmp/potpaw'\n</code></pre> <p>The cell below loads the pseudo potentials from the path specified above. Since you can only upload them once, we once again wrap the cell in a <code>try</code>-<code>except</code> block.</p> <pre><code>from aiida_vasp.data.potcar import PotcarData\n\ntry:\n    orm.load_group('PBE.64')\nexcept NotExistent:\n    PotcarData.upload_potcar_family(\n        source=path_to_potcar_files,\n        group_name='PBE.64',\n        group_description='Family of the v64 pseudo potentials for VASP.'\n    );\n</code></pre> <ul> <li> <p>\u2705 All done!</p> <p>You should now be ready to run your first workflow! Proceed to the quickstart tutorial.</p> <p>\u2192 Go to the tutorial</p> </li> </ul>"}]}